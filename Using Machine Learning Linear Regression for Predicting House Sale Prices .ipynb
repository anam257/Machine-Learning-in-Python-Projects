{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "\n",
    "In this project, I am working on housing data for the city of Ames, Iowa, United States from 2006 to 2010. More infromation of the data can be read [here](https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627). Information the different columns in the data can be read [here](https://s3.amazonaws.com/dq-content/307/data_description.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "\n",
    "houses=pd.read_csv(\"AmesHousing.tsv\",delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(houses):\n",
    "    return houses\n",
    "\n",
    "def select_features(houses):\n",
    "    return houses[[\"Gr Liv Area\",\"SalePrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
       "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       5    2010       WD           Normal     215000  \n",
       "1        0       6    2010       WD           Normal     105000  \n",
       "2    12500       6    2010       WD           Normal     172000  \n",
       "3        0       4    2010       WD           Normal     244000  \n",
       "4        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform column names by removing whitespaces\n",
    "houses.columns = houses.columns.str.strip()\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(df):\n",
    "    train=df[:1460]\n",
    "    test=df[1460:]\n",
    "\n",
    "    numeric_train=train.select_dtypes(include=[\"integer\",\"float\"])\n",
    "    numeric_test=test.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    print(features)\n",
    "    lr=LinearRegression()\n",
    "    model=lr.fit(train[features],train[\"SalePrice\"])\n",
    "    predictions=model.predict(test[features])\n",
    "    mse=mean_squared_error(test[\"SalePrice\"],predictions)\n",
    "    rmse=mse**(0.5)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gr Liv Area'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_houses = transform_features(houses)\n",
    "filtered_houses = select_features(transform_houses)\n",
    "rmse = train_and_test(filtered_houses)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Handle missing values:\n",
    "- All columns:\n",
    "    - Drop any with 5% or more missing values for now.\n",
    "- Text columns:\n",
    "    - Drop any with 1 or more missing values for now.\n",
    "- Numerical columns:\n",
    "    - For columns with missing values, fill in with the most common value in that column\n",
    "\n",
    "\n",
    "1: All columns: Drop any with 5% or more missing values for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pool QC            2917\n",
       "Misc Feature       2824\n",
       "Alley              2732\n",
       "Fence              2358\n",
       "Fireplace Qu       1422\n",
       "Lot Frontage        490\n",
       "Garage Qual         159\n",
       "Garage Yr Blt       159\n",
       "Garage Cond         159\n",
       "Garage Finish       159\n",
       "Garage Type         157\n",
       "Bsmt Exposure        83\n",
       "BsmtFin Type 2       81\n",
       "BsmtFin Type 1       80\n",
       "Bsmt Cond            80\n",
       "Bsmt Qual            80\n",
       "Mas Vnr Type         23\n",
       "Mas Vnr Area         23\n",
       "Bsmt Full Bath        2\n",
       "Bsmt Half Bath        2\n",
       "Garage Area           1\n",
       "Garage Cars           1\n",
       "Total Bsmt SF         1\n",
       "Bsmt Unf SF           1\n",
       "BsmtFin SF 2          1\n",
       "BsmtFin SF 1          1\n",
       "Electrical            1\n",
       "Exterior 2nd          0\n",
       "Exterior 1st          0\n",
       "Roof Matl             0\n",
       "                   ... \n",
       "Heating               0\n",
       "Exter Cond            0\n",
       "Functional            0\n",
       "Sale Type             0\n",
       "Yr Sold               0\n",
       "Mo Sold               0\n",
       "Misc Val              0\n",
       "Pool Area             0\n",
       "Screen Porch          0\n",
       "3Ssn Porch            0\n",
       "Enclosed Porch        0\n",
       "Open Porch SF         0\n",
       "Wood Deck SF          0\n",
       "Paved Drive           0\n",
       "Fireplaces            0\n",
       "TotRms AbvGrd         0\n",
       "Foundation            0\n",
       "Kitchen Qual          0\n",
       "Kitchen AbvGr         0\n",
       "Bedroom AbvGr         0\n",
       "Half Bath             0\n",
       "Full Bath             0\n",
       "Gr Liv Area           0\n",
       "Low Qual Fin SF       0\n",
       "2nd Flr SF            0\n",
       "1st Flr SF            0\n",
       "Central Air           0\n",
       "Heating QC            0\n",
       "Sale Condition        0\n",
       "Order                 0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding percentage of missing values in columns in descending order\n",
    "missing_values=houses.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Fireplace Qu',\n",
       "       'Lot Frontage', 'Garage Qual', 'Garage Yr Blt', 'Garage Cond',\n",
       "       'Garage Finish', 'Garage Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter columns that has missing values >5%\n",
    "drop_cols=missing_values[(missing_values>len(houses)/20)].index\n",
    "\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove 'Pool QC', 'Misc Feature', 'Alley', 'Fence', 'Fireplace Qu',\n",
    "       'Lot Frontage', 'Garage Qual', 'Garage Yr Blt', 'Garage Cond',\n",
    "       'Garage Finish', 'Garage Type' columns as they have more than 5% of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses=houses.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Text columns: Drop any with 1 or more missing values for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Series object: column name -> number of missing values\n",
    "text_missing_cols = houses.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "## Filter Series to columns containing *any* missing values\n",
    "drop_missing_cols_2 = text_missing_cols[text_missing_cols > 0]\n",
    "drop_missing_cols_2\n",
    "houses = houses.drop(drop_missing_cols_2.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Numerical columns: For columns with missing values, fill in with the most common value in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1       1\n",
       "BsmtFin SF 2       1\n",
       "Bsmt Unf SF        1\n",
       "Total Bsmt SF      1\n",
       "Garage Cars        1\n",
       "Garage Area        1\n",
       "Bsmt Full Bath     2\n",
       "Bsmt Half Bath     2\n",
       "Mas Vnr Area      23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute column-wise missing value counts\n",
    "num_missing = houses.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "fixable_numeric_cols = num_missing[(num_missing < len(houses)/20) & (num_missing > 0)].sort_values()\n",
    "fixable_numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BsmtFin SF 1': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'Total Bsmt SF': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'Garage Area': 0.0,\n",
       " 'Bsmt Full Bath': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Mas Vnr Area': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute the most common value for each column in `fixable_nmeric_missing_cols`.\n",
    "replacement_values_dict = houses[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "replacement_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses=houses.fillna(replacement_values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Verify that every column has 0 missing values\n",
    "houses.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new columns\n",
    "For instance,Yr Sold and Year Built are discrete values with which we can't make much inference and relevance to our data. So,converting them to creating a meaningful information would help with our model.\n",
    "\n",
    "The two main issues with these features are:\n",
    "\n",
    "- Year values aren't representative of how old a house is\n",
    "- The Year Remod/Add column doesn't actually provide useful information for a linear regression model\n",
    "\n",
    "The challenge with year values like 1960 and 1961 is that they don't do a good job of capturing how old a house is. \n",
    "Instead of the years certain events happened, we want the difference between those years. We should create a new column that's the difference between both of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives information before sold\n",
    "years_sold = houses['Yr Sold'] - houses['Year Built']\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives information years since remodel\n",
    "\n",
    "years_since_remod = houses['Yr Sold'] - houses['Year Remod/Add']\n",
    "years_since_remod[years_since_remod < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop rows with negative values \n",
    "houses.drop([1780,2180,2181],axis=0)\n",
    "\n",
    "houses[\"year_before_sold\"]=years_sold\n",
    "houses[\"year_since_remodel\"]=years_since_remod\n",
    "\n",
    "# Drop those yr built,yr remodel cols\n",
    "\n",
    "houses=houses.drop(['Year Remod/Add','Year Built'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove columns that leak information\n",
    "\n",
    "More information on features of the dataset can be found [here](https://s3.amazonaws.com/dq-content/307/data_description.txt)\n",
    "\n",
    "- Drop the columns that doesn't provide infromation to ML model. Ex: PID, Order columns\n",
    "- Drop the columns that have potential to leak information on final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After a quick look at the dataset, we found that:\n",
    "\n",
    "- In numerical columns, there are columns of which values are obviously not directly related to the sale price. We should drop these columns: Order, PID.\n",
    "-  There are missing values in a few numerical columns. For the 8 columns that only have one or two missing values, we can just drop the rows. For the rest numerical columns with missing values, after checking, we can inpute the columns with their mean.\n",
    "- There are a few non-numerical columns contain a lot of null values like Pool QC. Considering the large amount of missing data, we should just drop those columns. We will arbitrarily set the cut-off of at 25%.\n",
    "-  From the frequency table of non-numerical columns, we can tell all of them are categorical, and that's what we will transform them into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses=houses.drop([\"Mo Sold\",\"Sale Type\", \"Yr Sold\",\"Sale Condition\",\"Order\",\"PID\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MS SubClass', 'MS Zoning', 'Lot Area', 'Street', 'Lot Shape',\n",
       "       'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood',\n",
       "       'Condition 1', 'Condition 2', 'Bldg Type', 'House Style',\n",
       "       'Overall Qual', 'Overall Cond', 'Roof Style', 'Roof Matl',\n",
       "       'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Area', 'Exter Qual',\n",
       "       'Exter Cond', 'Foundation', 'BsmtFin SF 1', 'BsmtFin SF 2',\n",
       "       'Bsmt Unf SF', 'Total Bsmt SF', 'Heating', 'Heating QC', 'Central Air',\n",
       "       '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area',\n",
       "       'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath',\n",
       "       'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual', 'TotRms AbvGrd',\n",
       "       'Functional', 'Fireplaces', 'Garage Cars', 'Garage Area', 'Paved Drive',\n",
       "       'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
       "       'Screen Porch', 'Pool Area', 'Misc Val', 'SalePrice',\n",
       "       'year_before_sold', 'year_since_remodel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MS SubClass', 'MS Zoning', 'Lot Area', 'Street', 'Lot Shape',\n",
      "       'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood',\n",
      "       'Condition 1', 'Condition 2', 'Bldg Type', 'House Style',\n",
      "       'Overall Qual', 'Overall Cond', 'Roof Style', 'Roof Matl',\n",
      "       'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Area', 'Exter Qual',\n",
      "       'Exter Cond', 'Foundation', 'BsmtFin SF 1', 'BsmtFin SF 2',\n",
      "       'Bsmt Unf SF', 'Total Bsmt SF', 'Heating', 'Heating QC', 'Central Air',\n",
      "       '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area',\n",
      "       'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath',\n",
      "       'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual', 'TotRms AbvGrd',\n",
      "       'Functional', 'Fireplaces', 'Garage Cars', 'Garage Area', 'Paved Drive',\n",
      "       'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch',\n",
      "       'Screen Porch', 'Pool Area', 'Misc Val', 'SalePrice',\n",
      "       'Years Before Sale', 'Years Since Remod'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55275.367312413066"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    # Transform column names by removing whitespaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Finding percentage of missing values in columns in descending order\n",
    "    num_missing = df.isnull().sum()\n",
    "    # drop columns with more than 5% missing values\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    \n",
    "    ## Series object: column name -> number of missing values\n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    ## Text Columns: Filter Series to columns containing *any* missing values\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "\n",
    "    ## Compute column-wise missing value counts\n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    ## Compute the most common value for each column in `fixable_nmeric_missing_cols`.\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    # Create New Columns\n",
    "    # Gives information before sold\n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    # Gives information years since remodel\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    ## Drop rows with negative values in new columns\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    \n",
    "    # Drop those yr sold,yr built,yr remodel cols,columns that leak information\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\",'Yr Sold', \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    print(df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):  \n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    ## You can use `pd.DataFrame.select_dtypes()` to specify column types\n",
    "    ## and return only those columns as a data frame.\n",
    "    numeric_train = train.select_dtypes(include=['integer', 'float'])\n",
    "    numeric_test = test.select_dtypes(include=['integer', 'float'])\n",
    "    \n",
    "    ## You can use `pd.Series.drop()` to drop a value.\n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2         0.006127\n",
       "Misc Val             0.019273\n",
       "3Ssn Porch           0.032268\n",
       "Bsmt Half Bath       0.035875\n",
       "Low Qual Fin SF      0.037629\n",
       "Pool Area            0.068438\n",
       "MS SubClass          0.085128\n",
       "Overall Cond         0.101540\n",
       "Screen Porch         0.112280\n",
       "Kitchen AbvGr        0.119760\n",
       "Enclosed Porch       0.128685\n",
       "Bedroom AbvGr        0.143916\n",
       "Bsmt Unf SF          0.182751\n",
       "Lot Area             0.267520\n",
       "2nd Flr SF           0.269601\n",
       "Bsmt Full Bath       0.276258\n",
       "Half Bath            0.284871\n",
       "Open Porch SF        0.316262\n",
       "Wood Deck SF         0.328183\n",
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years Since Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat=transform_df.select_dtypes(include=['integer', 'float'])\n",
    "corr_wrt_saleprice=corrmat.corr()[\"SalePrice\"].abs().sort_values()\n",
    "corr_wrt_saleprice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep columns that have correlation coefficient larger than 0.4 (we can set our cutoff,its worth experimenting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1         0.439284\n",
       "Fireplaces           0.474831\n",
       "TotRms AbvGrd        0.498574\n",
       "Mas Vnr Area         0.506983\n",
       "Years Since Remod    0.534985\n",
       "Full Bath            0.546118\n",
       "Years Before Sale    0.558979\n",
       "1st Flr SF           0.635185\n",
       "Garage Area          0.641425\n",
       "Total Bsmt SF        0.644012\n",
       "Garage Cars          0.648361\n",
       "Gr Liv Area          0.717596\n",
       "Overall Qual         0.801206\n",
       "SalePrice            1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_wrt_saleprice[corr_wrt_saleprice>0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_df=transform_df.drop(corr_wrt_saleprice[corr_wrt_saleprice<=0.4].index,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming non-numeric columns into categorical datatype\n",
    "\n",
    "To do the transformation,we need to follow the steps\n",
    "- Finding non-numeric columns and find unique values in the each of those features.\n",
    "- Setting a cutoff 10 unique values in each feature. Feature needs to be removed if unique count is more than 10. \n",
    "- Creating dummy features from the filtered features and should be added back to our dataframe and also we should remove the original columns related to dummy features.\n",
    "\n",
    "Note:\n",
    "categorical columns have a few unique values but more than 95% of the values in the column belong to a specific category will low variance. This would be similar to a low variance numerical feature (no variability in the data for the model to capture). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "transform_cat_cols = []\n",
    "for col in cat_nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        transform_cat_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MS Zoning        7\n",
       "Street           2\n",
       "Land Contour     4\n",
       "Lot Config       5\n",
       "Neighborhood    28\n",
       "Condition 1      9\n",
       "Condition 2      8\n",
       "Bldg Type        5\n",
       "House Style      8\n",
       "Roof Style       6\n",
       "Roof Matl        8\n",
       "Exterior 1st    16\n",
       "Exterior 2nd    17\n",
       "Foundation       6\n",
       "Heating          6\n",
       "Central Air      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding count of unique values in non-numeric cols\n",
    "unique_nonnumeric_count=transform_df[transform_cat_cols].apply(lambda col:len(col.value_counts()))\n",
    "unique_nonnumeric_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features more than 10 unique values\n",
    "transform_df=transform_df.drop(unique_nonnumeric_count[unique_nonnumeric_count>10].index,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_cols=transform_df.select_dtypes(include=[\"object\"])\n",
    "# Converting nominal to categorical features\n",
    "for col in text_cols:\n",
    "    transform_df[col]=transform_df[col].astype(\"category\")\n",
    "\n",
    "# Create dummy variables for caterogrical features\n",
    "transform_df=pd.concat([\n",
    "    transform_df, \n",
    "    pd.get_dummies(transform_df.select_dtypes(include=['category']))\n",
    "], axis=1)\n",
    "transform_df=transform_df.drop(text_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       215000\n",
       "1       105000\n",
       "2       172000\n",
       "3       244000\n",
       "4       189900\n",
       "5       195500\n",
       "6       213500\n",
       "7       191500\n",
       "8       236500\n",
       "9       189000\n",
       "10      175900\n",
       "11      185000\n",
       "12      180400\n",
       "13      171500\n",
       "14      212000\n",
       "15      538000\n",
       "16      164000\n",
       "17      394432\n",
       "18      141000\n",
       "19      210000\n",
       "20      190000\n",
       "21      170000\n",
       "22      216000\n",
       "23      149000\n",
       "24      149900\n",
       "25      142000\n",
       "26      126000\n",
       "27      115000\n",
       "28      184000\n",
       "29       96000\n",
       "         ...  \n",
       "2900    320000\n",
       "2901    369900\n",
       "2902    359900\n",
       "2903     81500\n",
       "2904    215000\n",
       "2905    164000\n",
       "2906    153500\n",
       "2907     84500\n",
       "2908    104500\n",
       "2909    127000\n",
       "2910    151400\n",
       "2911    126500\n",
       "2912    146500\n",
       "2913     73000\n",
       "2914     79400\n",
       "2915    140000\n",
       "2916     92000\n",
       "2917     87550\n",
       "2918     79500\n",
       "2919     90500\n",
       "2920     71000\n",
       "2921    150900\n",
       "2922    188000\n",
       "2923    160000\n",
       "2924    131000\n",
       "2925    142500\n",
       "2926    131000\n",
       "2927    132000\n",
       "2928    170000\n",
       "2929    188000\n",
       "Name: SalePrice, Length: 2927, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33367.28718340389"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=train_and_test(transform_df)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28832.51424964921"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    # Transform column names by removing whitespaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Finding percentage of missing values in columns in descending order\n",
    "    num_missing = df.isnull().sum()\n",
    "    # drop columns with more than 5% missing values\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    \n",
    "    ## Series object: column name -> number of missing values\n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    ## Text Columns: Filter Series to columns containing *any* missing values\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "\n",
    "    ## Compute column-wise missing value counts\n",
    "    num_missing = df.select_dtypes(include=['int', 'float']).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    ## Compute the most common value for each column in `fixable_nmeric_missing_cols`.\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    # Create New Columns\n",
    "    # Gives information before sold\n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    # Gives information years since remodel\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    ## Drop rows with negative values in new columns\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    \n",
    "    # Drop those yr sold,yr built,yr remodel cols,columns that leak information\n",
    "\n",
    "    df = df.drop([\"PID\", 'Yr Sold',\"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, uniq_threshold=10):\n",
    "    corrmat=df.select_dtypes(include=['integer', 'float'])\n",
    "    corr_wrt_saleprice=corrmat.corr()[\"SalePrice\"].abs().sort_values()\n",
    "    df=df.drop(corr_wrt_saleprice[corr_wrt_saleprice<=0.4].index,axis=1)\n",
    "    \n",
    "    ## Create a list of column names from documentation that are *meant* to be categorical\n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "    #Finding count of unique values in non-numeric cols\n",
    "    unique_nonnumeric_count=df[transform_cat_cols].apply(lambda col:len(col.value_counts())).sort_values()\n",
    "    \n",
    "    # drop nominal features with more than uniq_threshold\n",
    "    drop_nonuniq_cols = unique_nonnumeric_count[unique_nonnumeric_count > uniq_threshold].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        # Converting nominal to categorical features\n",
    "        df[col] = df[col].astype('category')\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=0):\n",
    "\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    lr = LinearRegression()\n",
    "    np.random.seed(1)\n",
    "    if k == 0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_test = lr.predict(test[features])\n",
    "        # Out sample error\n",
    "        mse_test = mean_squared_error(test[\"SalePrice\"], predictions_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        \n",
    "        #in sample error\n",
    "        predictions_train = lr.predict(train[features])\n",
    "        mse_train= mean_squared_error(train[\"SalePrice\"], predictions_train)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        var_test=np.var(predictions_test)\n",
    "\n",
    "        return [rmse_test,rmse_train,var_test]\n",
    "    \n",
    "    if k == 1:\n",
    "        # Randomize *all* rows (frac=1) from `df` and return\n",
    "        #specifying drop=True prevents .reset_index from creating a column containing the old index entries.\n",
    "        shuffled_df = df.sample(frac=1, ).reset_index(drop=True)\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_one_test = lr.predict(test[features])        \n",
    "        # out sample error\n",
    "        mse_one_test = mean_squared_error(test[\"SalePrice\"], predictions_one_test)\n",
    "        rmse_one_test = np.sqrt(mse_one_test)\n",
    "        var_one=np.mean(predictions_one_test)\n",
    "    \n",
    "        # in sample error\n",
    "        predictions_one_train = lr.predict(train[features])\n",
    "        mse_one_train = mean_squared_error(train[\"SalePrice\"], predictions_one_train)\n",
    "        rmse_one_train = np.sqrt(mse_one_train)\n",
    "        \n",
    "        lr.fit(test[features], test[\"SalePrice\"])\n",
    "        predictions_two_test = lr.predict(train[features])    \n",
    "        # out sample error\n",
    "        mse_two_test = mean_squared_error(train[\"SalePrice\"], predictions_two_test)\n",
    "        rmse_two_test  = np.sqrt(mse_two_test )\n",
    "        \n",
    "        # in sample error\n",
    "        predictions_two_train = lr.predict(test[features])\n",
    "        mse_two_train = mean_squared_error(test[\"SalePrice\"], predictions_two_train)\n",
    "        rmse_two_train = np.sqrt(mse_two_train)\n",
    "        var_two=np.mean(predictions_two_test)\n",
    "        avg_rmse_test= np.mean([rmse_one_test, rmse_two_test])\n",
    "        avg_rmse_train= np.mean([rmse_one_train, rmse_two_train])\n",
    "        avg_var=np.mean([var_one,var_two])\n",
    "        return [avg_rmse_test,avg_rmse_train,avg_var]\n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values_test = []\n",
    "        rmse_values_train = []\n",
    "        var_values_test=[]\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            # predicting for test dataset\n",
    "            predictions_test = lr.predict(test[features])\n",
    "            mse_test = mean_squared_error(test[\"SalePrice\"], predictions_test)\n",
    "            rmse_test = np.sqrt(mse_test)\n",
    "            rmse_values_test.append(rmse_test)\n",
    "            # Predicting for training dataset\n",
    "            predictions_train = lr.predict(train[features])\n",
    "            mse_train = mean_squared_error(train[\"SalePrice\"], predictions_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            rmse_values_train.append(rmse_train)\n",
    "            \n",
    "            # Variance calculation for test set \n",
    "            var_test=np.var(predictions_test)\n",
    "            var_values_test.append(var_test)\n",
    "        # Calculating in-sample-error (training on train dataset)\n",
    "        avg_rmse_test = np.mean(rmse_values_test)\n",
    "                \n",
    "        # Calculating out-sample-error (training on train dataset)\n",
    "        avg_rmse_train = np.mean(rmse_values_train)\n",
    "        \n",
    "        # Average Variance\n",
    "        avg_var=np.mean(var_values_test)\n",
    "        return [avg_rmse_test,avg_rmse_train,avg_var]\n",
    "\n",
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse=train_and_test(filtered_df, k=5)[0]\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfold_avg_rmse_test={}\n",
    "kfold_avg_rmse_train={}\n",
    "kfold_avg_var=[]\n",
    "for k in range(0,31):\n",
    "    df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "    transform_df = transform_features(df)\n",
    "    filtered_df = select_features(transform_df)\n",
    "    model_values=train_and_test(filtered_df, k=k)\n",
    "    kfold_avg_rmse_test[k]=model_values[0]\n",
    "    kfold_avg_rmse_train[k]=model_values[1]\n",
    "    kfold_avg_var.append(model_values[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K_Folds</th>\n",
       "      <th>Avg_rmse_test</th>\n",
       "      <th>Avg_rmse_train</th>\n",
       "      <th>Avg_var</th>\n",
       "      <th>Error_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33367.287183</td>\n",
       "      <td>23178.242653</td>\n",
       "      <td>5.567576e+09</td>\n",
       "      <td>10189.044530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30261.212834</td>\n",
       "      <td>23789.624698</td>\n",
       "      <td>1.810992e+05</td>\n",
       "      <td>6471.588136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29785.012118</td>\n",
       "      <td>23912.753647</td>\n",
       "      <td>5.976302e+09</td>\n",
       "      <td>5872.258471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>29482.539430</td>\n",
       "      <td>24246.472566</td>\n",
       "      <td>5.949229e+09</td>\n",
       "      <td>5236.066864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>29111.434973</td>\n",
       "      <td>24387.656118</td>\n",
       "      <td>5.947165e+09</td>\n",
       "      <td>4723.778855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>28832.514250</td>\n",
       "      <td>24437.422137</td>\n",
       "      <td>5.936472e+09</td>\n",
       "      <td>4395.092113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>28702.689556</td>\n",
       "      <td>24473.504443</td>\n",
       "      <td>5.913157e+09</td>\n",
       "      <td>4229.185113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>28592.540428</td>\n",
       "      <td>24504.842607</td>\n",
       "      <td>5.926215e+09</td>\n",
       "      <td>4087.697822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>28555.990293</td>\n",
       "      <td>24516.445309</td>\n",
       "      <td>5.910527e+09</td>\n",
       "      <td>4039.544984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>28476.629925</td>\n",
       "      <td>24523.735160</td>\n",
       "      <td>5.930357e+09</td>\n",
       "      <td>3952.894766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>28361.902839</td>\n",
       "      <td>24530.277912</td>\n",
       "      <td>5.932995e+09</td>\n",
       "      <td>3831.624927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>28298.072645</td>\n",
       "      <td>24543.950782</td>\n",
       "      <td>5.918609e+09</td>\n",
       "      <td>3754.121863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>28224.973256</td>\n",
       "      <td>24548.197855</td>\n",
       "      <td>5.925456e+09</td>\n",
       "      <td>3676.775401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>28133.582975</td>\n",
       "      <td>24552.623865</td>\n",
       "      <td>5.924603e+09</td>\n",
       "      <td>3580.959110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>28260.402190</td>\n",
       "      <td>24556.969093</td>\n",
       "      <td>5.923627e+09</td>\n",
       "      <td>3703.433097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>28049.720612</td>\n",
       "      <td>24562.313903</td>\n",
       "      <td>5.920598e+09</td>\n",
       "      <td>3487.406709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>28241.549969</td>\n",
       "      <td>24565.440724</td>\n",
       "      <td>5.922370e+09</td>\n",
       "      <td>3676.109245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>28121.932202</td>\n",
       "      <td>24567.727661</td>\n",
       "      <td>5.920800e+09</td>\n",
       "      <td>3554.204541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>27755.744313</td>\n",
       "      <td>24570.715441</td>\n",
       "      <td>5.921142e+09</td>\n",
       "      <td>3185.028872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>27727.815703</td>\n",
       "      <td>24570.966904</td>\n",
       "      <td>5.915612e+09</td>\n",
       "      <td>3156.848799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>27612.953154</td>\n",
       "      <td>24573.419611</td>\n",
       "      <td>5.921359e+09</td>\n",
       "      <td>3039.533543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>27598.201090</td>\n",
       "      <td>24576.909404</td>\n",
       "      <td>5.905575e+09</td>\n",
       "      <td>3021.291687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>27536.763754</td>\n",
       "      <td>24577.829048</td>\n",
       "      <td>5.911035e+09</td>\n",
       "      <td>2958.934706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>27474.802076</td>\n",
       "      <td>24580.064466</td>\n",
       "      <td>5.913587e+09</td>\n",
       "      <td>2894.737610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>27465.065620</td>\n",
       "      <td>24581.142118</td>\n",
       "      <td>5.910289e+09</td>\n",
       "      <td>2883.923502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>27418.610671</td>\n",
       "      <td>24583.158122</td>\n",
       "      <td>5.908219e+09</td>\n",
       "      <td>2835.452549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>27514.003260</td>\n",
       "      <td>24583.239125</td>\n",
       "      <td>5.912936e+09</td>\n",
       "      <td>2930.764134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27387.196996</td>\n",
       "      <td>24584.728458</td>\n",
       "      <td>5.913011e+09</td>\n",
       "      <td>2802.468537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>27392.609202</td>\n",
       "      <td>24585.447352</td>\n",
       "      <td>5.918050e+09</td>\n",
       "      <td>2807.161850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>27387.044957</td>\n",
       "      <td>24586.543926</td>\n",
       "      <td>5.903322e+09</td>\n",
       "      <td>2800.501031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>27360.643612</td>\n",
       "      <td>24586.871657</td>\n",
       "      <td>5.897810e+09</td>\n",
       "      <td>2773.771955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K_Folds  Avg_rmse_test  Avg_rmse_train       Avg_var    Error_diff\n",
       "0         0   33367.287183    23178.242653  5.567576e+09  10189.044530\n",
       "1         1   30261.212834    23789.624698  1.810992e+05   6471.588136\n",
       "2         2   29785.012118    23912.753647  5.976302e+09   5872.258471\n",
       "3         3   29482.539430    24246.472566  5.949229e+09   5236.066864\n",
       "4         4   29111.434973    24387.656118  5.947165e+09   4723.778855\n",
       "5         5   28832.514250    24437.422137  5.936472e+09   4395.092113\n",
       "6         6   28702.689556    24473.504443  5.913157e+09   4229.185113\n",
       "7         7   28592.540428    24504.842607  5.926215e+09   4087.697822\n",
       "8         8   28555.990293    24516.445309  5.910527e+09   4039.544984\n",
       "9         9   28476.629925    24523.735160  5.930357e+09   3952.894766\n",
       "10       10   28361.902839    24530.277912  5.932995e+09   3831.624927\n",
       "11       11   28298.072645    24543.950782  5.918609e+09   3754.121863\n",
       "12       12   28224.973256    24548.197855  5.925456e+09   3676.775401\n",
       "13       13   28133.582975    24552.623865  5.924603e+09   3580.959110\n",
       "14       14   28260.402190    24556.969093  5.923627e+09   3703.433097\n",
       "15       15   28049.720612    24562.313903  5.920598e+09   3487.406709\n",
       "16       16   28241.549969    24565.440724  5.922370e+09   3676.109245\n",
       "17       17   28121.932202    24567.727661  5.920800e+09   3554.204541\n",
       "18       18   27755.744313    24570.715441  5.921142e+09   3185.028872\n",
       "19       19   27727.815703    24570.966904  5.915612e+09   3156.848799\n",
       "20       20   27612.953154    24573.419611  5.921359e+09   3039.533543\n",
       "21       21   27598.201090    24576.909404  5.905575e+09   3021.291687\n",
       "22       22   27536.763754    24577.829048  5.911035e+09   2958.934706\n",
       "23       23   27474.802076    24580.064466  5.913587e+09   2894.737610\n",
       "24       24   27465.065620    24581.142118  5.910289e+09   2883.923502\n",
       "25       25   27418.610671    24583.158122  5.908219e+09   2835.452549\n",
       "26       26   27514.003260    24583.239125  5.912936e+09   2930.764134\n",
       "27       27   27387.196996    24584.728458  5.913011e+09   2802.468537\n",
       "28       28   27392.609202    24585.447352  5.918050e+09   2807.161850\n",
       "29       29   27387.044957    24586.543926  5.903322e+09   2800.501031\n",
       "30       30   27360.643612    24586.871657  5.897810e+09   2773.771955"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_rmse_df=pd.DataFrame(kfold_avg_rmse_test.items(), columns=['K_Folds', 'Avg_rmse_test'])\n",
    "\n",
    "k_fold_rmse_df[\"Avg_rmse_train\"]=k_fold_rmse_df[\"K_Folds\"].map(kfold_avg_rmse_train)\n",
    "k_fold_rmse_df[\"Avg_var\"]=kfold_avg_var\n",
    "k_fold_rmse_df[\"Error_diff\"]=k_fold_rmse_df[\"Avg_rmse_test\"]-k_fold_rmse_df[\"Avg_rmse_train\"]\n",
    "k_fold_rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k_value=k_fold_rmse_df[(k_fold_rmse_df[\"Avg_rmse_test\"]==np.min(k_fold_rmse_df[\"Avg_rmse_test\"]))]\n",
    "best_k_value=best_k_value[\"K_Folds\"].values\n",
    "best_k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation with 30 kfolds resulted lowest average rmse of 27360.643611856955\n"
     ]
    }
   ],
   "source": [
    "lowest_rmse = min(k_fold_rmse_df[\"Avg_rmse_test\"])\n",
    "print(\"The cross validation with {} kfolds resulted lowest average rmse of {}\".format(best_k_value[0],lowest_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Before feature transformation and selection the average RMSE was 57088. Later, after the feature transformation, I was able to reduce RMSE to 55275.By removing the features which had potential to leak data and correlation value lower than 0.4, the RMSE  reduced to 33367. \n",
    "\n",
    "- Variance of the model at kfold 1 is lowest. But, we need to understand that as the models complexity increases error decrease and variance increase. We should decide what are the trade-offs for our model. \n",
    "- So, it always best to have a lowest error model with optimal variance.\n",
    "\n",
    "- The model developed in this project has reduce the rmse value by 52%. Finally, by using various k values for cross validation, I was able to optimize the model at k value of 30 which resulted in average rmse of 27361.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
